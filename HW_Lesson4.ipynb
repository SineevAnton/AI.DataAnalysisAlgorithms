{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урок 4. Алгоритм построения дерева решений\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Задачи:\n",
    "В коде из методички реализуйте один или несколько критериев останова: количество листьев, количество используемых признаков, глубина дерева и т. д.\n",
    "Реализуйте дерево для задачи регрессии. Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_u5bV-OlT34p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Основной код методички и семинара\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет прироста информации\n",
    "\n",
    "def gain(left_labels, right_labels, root_criterion, criterion):\n",
    "\n",
    "    # доля выборки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return root_criterion - p * criterion(left_labels) - (1 - p) * criterion(right_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение датасета в узле.\n",
    "# Генерация ветвей\n",
    "\n",
    "def split(data, labels, column_index, t):\n",
    "    \n",
    "    left = np.where(data[:, column_index] <= t)\n",
    "    right = np.where(data[:, column_index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    \n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return predict_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return predict_object(obj, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, tree):\n",
    "    \n",
    "    preds = []\n",
    "    for obj in data:\n",
    "        prediction = predict_object(obj, tree)\n",
    "        preds.append(prediction)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напечатаем ход нашего дерева\n",
    "def print_tree(node, spacing=\"\"):\n",
    "\n",
    "    # Если лист, то выводим его прогноз\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Прогноз:\", node.prediction)\n",
    "        return\n",
    "\n",
    "    # Выведем значение индекса и порога на этом узле\n",
    "    print(spacing + 'Индекс', str(node.index), '<=', str(node.t))\n",
    "\n",
    "    # Рекурсивный вызов функции на положительном поддереве\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Рекурсивный вызов функции на отрицательном поддереве\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Реализуйте дерево для задачи регрессии. Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "data, targets = make_regression(n_features=2, n_informative=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "train_data_regr, test_data_regr, train_target_regr, test_target_regr = train_test_split(data, \n",
    "                                                                                        targets, \n",
    "                                                                                        test_size=0.3,\n",
    "                                                                                        random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И класс терминального узла (листа)\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        # заменяем метод предсказания с поиска класса с максимальным количеством объектов на расчет среднего по выборке\n",
    "        return self.targets.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вместо критерия Джини используем дисперсию\n",
    "def mse(targets):\n",
    "    return np.mean((targets - targets.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "def find_best_split(data, targets):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_samples_leaf = 10\n",
    "\n",
    "    root_mse = mse(targets)\n",
    "\n",
    "    best_gain = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_targets, false_targets = split(data, targets, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 10 объектов\n",
    "            if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_gain = gain(true_targets, false_targets, root_mse, mse)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_gain > best_gain:\n",
    "                best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "    return best_gain, best_t, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "def build_tree(data, target, max_leaf_count = 20):\n",
    "\n",
    "    gain, t, index = find_best_split(data, target)\n",
    "    # обозначим максимальное количество листов дерева\n",
    "    current_leaf_count = max_leaf_count\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    # или достигли максимального количества листов\n",
    "    if gain == 0 or  current_leaf_count == 0:\n",
    "        return Leaf(data, target)\n",
    "\n",
    "    true_data, false_data, true_target, false_target = split(data, target, index, t)\n",
    "    current_leaf_count -= 1\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree(true_data, true_target, current_leaf_count)\n",
    "    false_branch = build_tree(false_data, false_target, current_leaf_count)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 1 <= 0.05080775477602897\n",
      "--> True:\n",
      "  Прогноз: -45.958447258279115\n",
      "--> False:\n",
      "  Прогноз: 69.1648359678289\n"
     ]
    }
   ],
   "source": [
    "# Построим дерево по обучающей выборке\n",
    "# Чтобы получить разные деревья и метрики - можно поиграться с последним аргументом функции\n",
    "# отвечающим за максимальное количество листьев (специально оставил 1 показать работоспособность)\n",
    "my_tree = build_tree(train_data_regr, train_target_regr, 1)\n",
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6138147507633414\n",
      "0.5946944399849461\n"
     ]
    }
   ],
   "source": [
    "train_answers = predict(train_data_regr, my_tree)\n",
    "train_r2 = r2_score(train_target_regr, train_answers)\n",
    "print(train_r2)\n",
    "\n",
    "answers = predict(test_data_regr, my_tree)\n",
    "test_r2 = r2_score(test_target_regr, answers)\n",
    "print(test_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
